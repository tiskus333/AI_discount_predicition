{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "# Projekt - Etap 2 - IUM 2021L\n",
    "*// Konrad Bratosiewicz // Mateusz Chruściel //* "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Budowa modelu\n",
    "## Dobór danych uczących\n",
    "Po wcześniejszej analizie danych do naszego modelu postanowiliśmy użyć:\n",
    "- liczby wizyt produktu\n",
    "- czas oglądania produktu w sekundach (znormalizowany metodą min-max)\n",
    "- liczba wejść na minutę\n",
    "- maksymalną zaoferowaną do tej pory zniżkę\n",
    "- aktualnie oferowaną zniżkę\n",
    "- czy klient zakupił finalnie przedmiot (-1 = nie, 1 = tak)\n",
    "\n",
    "## Założenia do wyników modelu\n",
    "Jak usaliliśmy podczas analizy danych żeby nasz model dawał sensowne wyniki musi przewidywać czy klient zakupi przedmiot z prawdopodobieństwem większym niż 57%, bo tyle wynosi prawdopodobieństwo wyboru klasy większościowej nie_kupił.\n",
    "\n",
    "## 1 Model zachłanny\n",
    "Pierwszy model daje zawszę zniżkę 20% bo gwarantuje ona przekonanie jak największej liczby osób\n",
    "\n",
    "## 2 Wyuczony model\n",
    "Na podstawie danych wejściowych uczymy model przewidywać czy dana \"produkto-sesja\" zakończy się zakupem. Model zwraca nam liczbę z przedziału <-1,1>. \n",
    "\n",
    "Dla takiego modelu by uzyskać predykcję zniżki wysyłamy zapytanie zawierające wszystkie dane ze wszystkimi możliwościami zniżki. Na przykład dla danych:\n",
    "```\n",
    "{\"d_time\":0.100068132,\"n_visits\":2,\"visits_per_minute\":0.0001321401,\"max_disc\":0,\"curr_disc\":0,\"is_purchased\":-1}\n",
    "```\n",
    "Zapytanie będzie wyglądało następująco:\n",
    "```\n",
    "[[0.100068132, 2, 0.0001321401, 0, 0],[0.100068132, 2, 0.0001321401, 0, 5],[0.100068132, 2, 0.0001321401, 0, 10],[0.100068132, 2, 0.0001321401, 0, 15],[0.100068132, 2, 0.0001321401, 0, 20]]\n",
    "```\n",
    "Przykładowa odpowiedź:\n",
    "```\n",
    "[-0.5271583795547485, 0.9961207509040833, 0.9995086789131165, 0.9996641874313354, 0.9995707273483276]\n",
    "```\n",
    "\n",
    "Model zwraca nam wtedy listę 5 liczb odpowiadającym według niego prawdopodobieństwu kupienia przedmiotu dla kolejnych zniżek. Finalna zniżka może być wybrana na wiele sposobów, my przygotowaliśmy 3 do porównania. \n",
    "\n",
    "Dokładna architektura oraz funkcje modelu w pliku model.py\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from random import randint\n",
    "\n",
    "from model import Model\n",
    "from load_data import load_data"
   ]
  },
  {
   "source": [
    "Załadowanie danych"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataLoader, test_dataLoader, = load_data(\"data3/normal_vpm.json\",batch_size=128,test_size=0.1)"
   ]
  },
  {
   "source": [
    "Stworzenie modelu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model()\n",
    "optimizer = optim.Adam(model1.parameters(),lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "source": [
    "Trenowanie modelu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Losses:   0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e6e3bd6c08641e7a659422b829510c8"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "model1.fit(train_dataLoader,optimizer,criterion,epochs=50)"
   ]
  },
  {
   "source": [
    "Testowanie modelu - zakładamy że model miał rację jeśli wartość absolutna wyniku jest większa niż próg"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Corectly predicted: 1813 out of 2034\nTest accuracy: 89.13%\n"
     ]
    }
   ],
   "source": [
    "model1.test(test_dataLoader,treshold=0.5)\n"
   ]
  },
  {
   "source": [
    "Otrzymaliśmy dokładność na poziomie powyżej 85%, więc możemy spokojnie założyć że nasz model rzeczywiście nauczył się rozpoznawać czy sesja zakończy się zakupem."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Opcje wyboru zniżki na podstawie wyników modelu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Opcja 1: Zniżka dla maksymalnego prawdopodobieństwa"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_discount1(discount_list):\n",
    "    return discount_list.index(max(discount_list)) * 5\n"
   ]
  },
  {
   "source": [
    "### Opcja 2: Zniżka, dla której prawdopodobieństwo zakupu jest większe niż określony próg"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_discount2(discount_list,threshold):\n",
    "    for i,disc in enumerate(discount_list):\n",
    "        if disc > threshold:\n",
    "            return i * 5\n",
    "    return i * 5"
   ]
  },
  {
   "source": [
    "### Opcja 3: Losowa zniżka dla której klient ma większe szanse, że kupi niż nie kupi"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_discount3(discount_list):\n",
    "    if max(discount_list) <= 0:\n",
    "        return 20\n",
    "    while True:\n",
    "        idx = randint(0,4)\n",
    "        if discount_list[idx] > 0:\n",
    "            return idx * 5\n",
    "        "
   ]
  },
  {
   "source": [
    "Pobranie wyników predykcji dla zniżek na podstawie danych testujących "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discounts(dataloader):\n",
    "    out = []\n",
    "    bought = 0\n",
    "    for X,Y in dataloader:\n",
    "        for y in Y:\n",
    "            if y > 0:\n",
    "                bought +=1\n",
    "        for x in X:\n",
    "            x_ = x.squeeze().tolist()[:4]\n",
    "            inp = torch.Tensor([x_ + [d*5] for d in range(5)])\n",
    "            out.append(model1(inp).squeeze().tolist())\n",
    "    return out, bought"
   ]
  },
  {
   "source": [
    "## Badanie średnich zniżek dla różnych opcji"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BOUGHT: 865 out of 2034\nOption 1: 18.68%\nOption 2: 13.606%\nOption 2: 15.691%\n"
     ]
    }
   ],
   "source": [
    "list1 = []\n",
    "list2 = []\n",
    "list3 = []\n",
    "disc_list, bought = get_discounts(test_dataLoader)\n",
    "for disc in disc_list:\n",
    "    list1.append(best_discount1(disc))\n",
    "    list2.append(best_discount2(disc,0.8))\n",
    "    list3.append(best_discount3(disc))\n",
    "print(f'BOUGHT: {bought} out of {len(test_dataLoader.dataset)}')\n",
    "print(f'Option 1: {np.average(list1):.5}%')\n",
    "print(f'Option 2: {np.average(list2):.5}%')\n",
    "print(f'Option 2: {np.average(list3):.5}%')\n"
   ]
  },
  {
   "source": [
    "Jak widać po powyższych wynikach niezależnie od wybranej opcji doboru zniżki zawsze otrzymujemy średnią zniżkę niższą niż 20%.\n",
    "\n",
    "Najlepsze wyniki ok 13.6% otrzymaliśmy dla opcji 2 tj. najniższa zniżka, dla której prawdopodobieństwo kupienia będzie wyższe niż zadany próg, w tym przypadku 0.8.\n",
    "\n",
    "Dzięki zastosowaniu naszego modelu zapewniamy te samo prawdopodobieństwo zakupu co przy dawaniu zawsze maksymalnej zniżki, redukując ją przy tym o dobre kilkadziesiąt procent. Oczywiście nie jesteśmy w stanie przeprowadzić testów w prawdziwym sklepie, więc na suchych danych nasz możliwości są dość ohraniczone, jednak wydaje nam się, że jest to wystarczający dowód działania naszego modelu."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}